import multiprocessing
import pathlib
from collections import Counter
from functools import partial, wraps

import angr
import dgl
import joblib
import networkx as nx
import numpy as np
import pandas as pd
import torch
from dgl.data import DGLDataset


# https://github.com/joblib/joblib/pull/366
def with_timeout(timeout):
    def decorator(decorated):
        @wraps(decorated)
        def inner(*args, **kwargs):
            pool = multiprocessing.pool.ThreadPool(1)
            async_result = pool.apply_async(decorated, args, kwargs)
            try:
                return async_result.get(timeout)
            except multiprocessing.TimeoutError:
                return

        return inner

    return decorator


possible_commands = ['push', 'mov', 'xor', 'call', 'sub',
                     'lea', 'and', 'pop', 'add', 'inc', 'dec',
                     'imul', 'idiv', 'or', 'not', 'neg', 'shl',
                     'shr', 'jmp', 'cmp', 'je', 'jne', 'jz',
                     'jg', 'jge', 'jl', 'jle', 'ret']


# TODO: add here ngrams features of sequences of cmds
def extract_block_diss_features(block_diss_str):
    """
    Extract the different counts for the different possible commands

    :param block_diss_str:
    :return:
    """
    commands = np.array([v.split('\t')[1] for v in block_diss_str.split('\n')])
    return np.array([len(np.where(commands == cmd)[0]) for cmd in possible_commands])


def extract_new_graph(cfg_graph):
    """
    Create a new CFG with the right block ids as the node ids
    """

    original_edgelist = nx.convert_matrix.to_pandas_edgelist(cfg_graph)
    source_idxs = original_edgelist['source'].apply(lambda x: x.block_id).values
    target_idxs = original_edgelist['target'].apply(lambda x: x.block_id).values
    new_edgelist = pd.DataFrame(np.hstack([source_idxs.reshape(-1, 1), target_idxs.reshape(-1, 1)]),
                                columns=['source', 'target'])
    new_graph = nx.convert_matrix.from_pandas_edgelist(new_edgelist)
    return new_graph


def extract_cfg_info(cfg_graph):
    """
    Given a CFG graph, extract nodal features

    :param cfg_graph:
    :return:
    """
    nodes_data = {}

    for i, node in enumerate(cfg_graph.nodes()):
        nodes_data[node.block_id] = {
            'id': node.block_id,
            'node': node,
            'str_name': str(node),
            'has_return': node.has_return,
            'is_simprocedure': node.is_simprocedure,
            'is_syscall': node.is_syscall,
            '#predecessors': len(node.predecessors),
            'size': node.size,
            '#successors': len(node.successors),
            'diss_data': str(node.block.disassembly) if node.size > 0 else None,
            'diss_features': extract_block_diss_features(str(node.block.disassembly)) if node.size > 0 else np.ones(
                28) * -1
        }

    return nodes_data


def load_sample_cfg(sample_path: pathlib.Path):
    """
    Given a path to a file - extract the CFG graph

    :param sample_path:
    :return:
    """
    proj = angr.Project(str(sample_path), load_options={'auto_load_libs': False})
    cfg = proj.analyses.CFGFast()
    return cfg.graph


@with_timeout(1800)
def handle_binary_to_dgl_graph(file_p, family_name):
    """
    Given a path for a binary file - extract the DGL graph of the CFG
    """
    try:
        sample_cfg = load_sample_cfg(file_p)
        sample_cfg_info = extract_cfg_info(sample_cfg)
        new_graph = extract_new_graph(sample_cfg)
        nx.set_node_attributes(new_graph, sample_cfg_info)
        g = dgl.from_networkx(new_graph,
                              node_attrs=['has_return', 'is_simprocedure', 'is_syscall', '#predecessors', 'size',
                                          '#successors', 'diss_features'])
    except Exception as e:
        return None
    return g, file_p.name, family_name


def load_graphs(folder_path: pathlib.Path, family_name):
    """
    Given a folder of files from a specific malware family - extract all of their CFG graphs
    """
    files = list(folder_path.glob('*'))
    run_func = partial(handle_binary_to_dgl_graph, family_name=family_name)
    jobs = [joblib.delayed(run_func)(file_p) for file_p in files]
    return jobs


class MalwareDataset(DGLDataset):
    """
    This is a dataset that represent 5 different malware families samples
    """

    def __init__(self, heodo_path, trickbot_path, agenttesla_path, dridex_path, loki_path):
        self.heodo_path = heodo_path
        self.trickbot_path = trickbot_path
        self.agenttesla_path = agenttesla_path
        self.dridex_path = dridex_path
        self.loki_path = loki_path

        super().__init__(name='malwares')

    def process(self):
        # Load the graphs and metadata of different malware families
        heodo_jobs = load_graphs(pathlib.Path(self.heodo_path), 'heodo')
        trickbot_jobs = load_graphs(pathlib.Path(self.trickbot_path), 'trickbot')
        agenttesla_jobs = load_graphs(pathlib.Path(self.agenttesla_path), 'agenttesla')
        dridex_jobs = load_graphs(pathlib.Path(self.dridex_path), 'dridex')
        loki_jobs = load_graphs(pathlib.Path(self.loki_path), 'loki')

        # Concat the resulted
        all_jobs = heodo_jobs + trickbot_jobs + agenttesla_jobs + dridex_jobs + loki_jobs

        # Split the results to graph, sha256 & malware family
        graphs_res = joblib.Parallel(n_jobs=10, verbose=100)(all_jobs)
        graphs_total = [g[0] for g in graphs_res if not g is None]
        sha256_total = [g[1] for g in graphs_res if not g is None]
        malwares_total = [g[2] for g in graphs_res if not g is None]

        # Count the final amounts parsed from each family
        malware_counts = Counter(malwares_total)

        self.graphs = graphs_total
        self.labels = np.hstack([np.zeros(malware_counts['heodo']), np.ones(malware_counts['trickbot']),
                                 np.ones(malware_counts['agenttesla']) * 2, np.ones(malware_counts['dridex']) * 3,
                                 np.ones(malware_counts['loki']) * 4])
        self.sha256 = sha256_total

    def __getitem__(self, i):
        return self.graphs[i], self.labels[i], self.sha256[i]

    def __len__(self):
        return len(self.graphs)


def _collate_fn(batch):
    """
    A collate function for creating the batch in training
    :param batch:
    :return:
    """
    graphs, labels, sha256 = [x[0] for x in batch], [x[1] for x in batch], [x[2] for x in batch]
    g = dgl.batch(graphs)
    labels = torch.tensor(labels, dtype=torch.long)
    return g, labels, sha256


class PairMalwareDataset(DGLDataset):
    def __init__(self, original_dataset, size):
        self.original_dataset = original_dataset
        self.size = size
        super().__init__(name='malwares')

    def process(self):
        self.first_sha256 = np.random.choice(self.original_dataset.sha256, size=self.size)
        self.first_graphs = [self.original_dataset.graphs[self.original_dataset.sha256.index(hash256)] for hash256 in
                             self.first_sha256]
        first_labels = [self.original_dataset.labels[self.original_dataset.sha256.index(hash256)] for hash256 in
                        self.first_sha256]

        self.second_sha256 = np.random.choice(self.original_dataset.sha256, size=self.size)
        self.second_graphs = [self.original_dataset.graphs[self.original_dataset.sha256.index(hash256)] for hash256 in
                              self.second_sha256]
        second_labels = [self.original_dataset.labels[self.original_dataset.sha256.index(hash256)] for hash256 in
                         self.second_sha256]

        self.labels = (np.array(first_labels) != np.array(second_labels)).astype(int)

    def __getitem__(self, i):
        return self.first_graphs[i], self.second_graphs[i], self.labels[i]

    def __len__(self):
        return len(self.first_graphs)


def _collate_fn_pairs(batch):
    first, second, labels = [x[0] for x in batch], [x[1] for x in batch], [x[2] for x in batch]
    g_first = dgl.batch(first)
    g_second = dgl.batch(second)
    labels = torch.tensor(labels, dtype=torch.long)
    return g_first, g_second, labels
